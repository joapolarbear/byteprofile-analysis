import os 
import ujson as json
import networkx as nx
import traceback
import time
import bisect
import collections

from dag_utils import QueueType
from trace_utils import *
from bps_helper.graph import *
from progress_utils import progressBar
import logger_utils
import debug_utils

FIXED_GAP_us = 5
args = arg_utils.SingleArg().args

class Device:
	def __init__(self, device_name, _replayer, infi_para=False, comm_backend = "NCCL"):
		self.replayer = _replayer
		self.device_time = 0
		self.device_name = device_name
		#! infi_para devices allow to excute in infinite parallelism
		self.infi_para = infi_para
		### Used to record the last event generated by this device
		self.prev_idx = None
		self.comm_backend = comm_backend

	def reset(self):
		self.device_time = 0
		self.prev_idx = None

	def exct(self, name, _last_end_time, step_idx):
		''' Execute one op on this device 

		Parameters
		----
		name: str
			The name of the op to run
		_last_end_time: float
			The time when this op can start to run, 
			i.e., all the dependent ops have been done
		'''
		### for debug
		debug_utils.DebugRecorder().debug_event_start()

		if not self.infi_para:
			_last_end_time = max(_last_end_time, self.device_time)

		if "Sync" in name or name == "END":
			#! No event is generated, but has successors
			self.mark_as_exct(name, _last_end_time, _last_end_time)
			return

		### Really start to execute
		avg = self.replayer.dag.nodes[name]["avg"]
		pid, raw_name, cat = parse_allinfo_from_name(name)
		delay, ratio = self.get_delay_para(name)
		duration = (1000.0 * max(avg + delay, 0)) * ratio

		### DEBUG: MANUALLY REDUCE COMM TIME
		# if cat == CatName.COMM.value:
		# 	duration /= 10

		if self.comm_backend == "BYTEPS" and "UPDATE_CAL" in name:
			duration = 0
		
		start_t = _last_end_time

		event = {
					"name": raw_name,
					"ts": start_t,
					"dur": duration,
					"pid": pid,
					"cat": cat,
					"ph": "X",
					"tid": cat,
					"args": {
						"name": name,
						"cnt": step_idx
					}
				}

		### Expose dependency info in trace["args"], time-consuming
		if args.full_trace:
			_id = 0
			for prev, _ in self.replayer.dag.in_edges(name):
				event["args"]["input%d"%_id] = prev
				_id += 1

		### Construct execution graphs
		### 1. Add new edges according to the execution order
		if self.prev_idx is not None:
			prev_event = self.replayer.rst_traces[self.prev_idx]
			if (prev_event["args"]["name"], name) not in self.replayer.exct_dag.edges:
				self.replayer.exct_dag.add_edge(prev_event["args"]["name"], name, weight=(prev_event["dur"] / 1000.0), exec_edges=True)
		self.prev_idx = len(self.replayer.rst_traces)

		# ### 2. Update edge weight
		# for next_ in self.replayer.exct_dag.successors(name):
		# 	self.replayer.exct_dag.edges[name, next_]["weight"] = duration / 1000.0

		self.replayer.rst_traces.append(event)
		debug_utils.DebugRecorder().debug_event_start()
		self.mark_as_exct(name, start_t, start_t + duration)
		debug_utils.DebugRecorder().debug_event_end(name, self.device_name, "mark_as_exct")
		### TODO (huhanpeng): modify after fine-tune update
		### Should be safe now, would be overitted by an UPDATE OP with larger UPDATE index
		# if "UPDATE" in name:
			#! current UPDATE of this GPU ends
		pid = parse_pid_from_name(name)
		self.replayer.step_end_time[pid] = start_t + duration

		#! TODO: for debug
		debug_utils.DebugRecorder().debug_event_end(name, self.device_name, "exct")
	
	def _update_device_time(self, name, _end_time):
		### Apply the gap between two nodes
		gap = 0
		for key, value in self.replayer.dag.nodes[name].items():
			if "GAP" in key:
				### e.g. "gap.operator.operator"
				key_s = key.split("GAP")
				### TODO (huhanpeng): does this fit to the BytePS or use intra-gap instead
				if key_s[0] == key_s[1]:
					gap += value
					if gap > 1000:
						SingleLogger().debug("Large GAP detected: {}, key = {}, gap = {}".format(name, key, value))
		if gap < 0:
			raise RuntimeError("Negative GAP detected: {}, key = {}, gap = {}".format(name, key, gap))
		self.device_time = _end_time + gap

	def mark_as_exct(self, name, _start_t, _end_time):
		''' Mark that the op has been executed '''

		self._update_device_time(name, _end_time)

		self.replayer.node_status.pop(name)
		this_cat = parse_cat_from_name(name)
		for _succ in self.replayer.dag.successors(name):
			next_cat = parse_cat_from_name(_succ)
			if _succ in self.replayer.node_status:
				_status = self.replayer.node_status[_succ]
				### Calculate the ready time
				if self.comm_backend == "NCCL" and ("SEND" in name and "RECV" in _succ):
					### For Send->Recv edge, there exist some overlap
					### TODO (huhanpeng): how do decide the end time of the RECV event
					avg = self.replayer.dag.nodes[_succ]["avg"]
					_status["ready"] = _end_time
				else:
					## For BYTEPS and Horovod, Only apply BW->Comm gaps
					## Other gaps should be considered with the device time.
					gap = 0
					if GAP_STR_OP2COMM in self.replayer.dag.nodes[name] and next_cat == CatName.COMM.value and this_cat == CatName.OPERATOR.value:
					# if GAP_STR_OP2COMM in self.replayer.dag.nodes[name] and next_cat == "Comm":
						gap += self.replayer.dag.nodes[name][GAP_STR_OP2COMM]
						if self.replayer.dag.nodes[name][GAP_STR_OP2COMM] > 10000:
							SingleLogger().warn("Large OP2COMM gap detected, {} -> {},  gap: {}".format(name, _succ, self.replayer.dag.nodes[name][GAP_STR_OP2COMM]))
					_status["ready"] = (_end_time + gap) if _status["ready"] is None else max(_end_time + gap, _status["ready"])
					

				### Whether the dependency has met
				_status["in_degree"] -= 1
				if _status["in_degree"] == 0:
					if _status["ready"] is None:
						raise RuntimeError("{}\'s ready time is not decided".format(_succ))
					self.replayer.insert_next_node(_succ, _status["ready"])

	def get_delay_para(self, name_):
		#! Get the delay parameters.
		delay = 0
		ratio = 1.0
		if self.replayer.delay_dict is not None:
			if name_ in self.replayer.delay_dict:
				delay = self.replayer.delay_dict[name_]["delay"]
				ratio = self.replayer.delay_dict[name_]["ratio"]
			elif "DELAY_ALL_CMP" in self.replayer.delay_dict and parse_cat_from_name(name_) == "operator":
				delay = self.replayer.delay_dict["DELAY_ALL_CMP"]["delay"]
				ratio = self.replayer.delay_dict["DELAY_ALL_CMP"]["ratio"]
			elif "DELAY_ALL_COMM" in self.replayer.delay_dict and parse_cat_from_name(name_) == CatName.COMM.value:
				delay = self.replayer.delay_dict["DELAY_ALL_COMM"]["delay"]
				ratio = self.replayer.delay_dict["DELAY_ALL_COMM"]["ratio"]
			elif "DELAY_ALL" in self.replayer.delay_dict:
				delay = self.replayer.delay_dict["DELAY_ALL"]["delay"]
				ratio = self.replayer.delay_dict["DELAY_ALL"]["ratio"]
		return delay, ratio

class PSCommDevice(Device):
	def __init__(self, device_name, _replayer, op_counter, comm_delay = 0, comm_backend = "NCCL", infi_para=False):
		super().__init__(device_name, _replayer, infi_para=infi_para, comm_backend = comm_backend)
		self.op_counter = op_counter
		self.comm_delay = comm_delay
		self.source = device_name.split("::")[0]
		self.target = device_name.split("::")[1].split(DEL)[0]
		

	# def exct(self, name, _last_end_time, step_idx):
	# 	if "PUSH_REQ" in name:
	# 		_last_end_time = max(_last_end_time + self.bw_delay, self.device_time)
	# 	super().exct(name, _last_end_time, step_idx)
	
	def mark_as_exct(self, name, _start_t, _end_time):
		next_name = self.op_counter.get_next_op(name)

		self._update_device_time(name, _end_time)

		self.replayer.node_status.pop(name)
		for _succ in self.replayer.dag.successors(name):
			if _succ in self.replayer.node_status:
				_status = self.replayer.node_status[_succ]
				_status["in_degree"] -= 1
				if _status["ready"] is None:
					if self.comm_delay and (self.source, self.target) in self.comm_delay:
						_status["ready"] = _end_time + self.comm_delay[(self.source, self.target)]
					else:
						_status["ready"] = _end_time
				else:
					if self.comm_delay and (self.source, self.target) in self.comm_delay:
						_status["ready"] = max(_end_time + self.comm_delay[(self.source, self.target)], _status["ready"])
					else:
						_status["ready"] = max(_end_time, _status["ready"])
				if _status["in_degree"] == 0:
					self.replayer.insert_next_node(_succ, _status["ready"])

		if next_name is not None:
			if next_name in self.replayer.node_status:
				_status = self.replayer.node_status[next_name]
				_status["in_degree"] -= 1
				if _status["ready"] is None:
					if self.comm_delay and (self.source, self.target) in self.comm_delay:
						_status["ready"] = _end_time + self.comm_delay[(self.source, self.target)]
					else:
						_status["ready"] = _end_time
				else:
					if self.comm_delay and (self.source, self.target) in self.comm_delay:
						_status["ready"] = max(_end_time + self.comm_delay[(self.source, self.target)], _status["ready"])
					else:
						_status["ready"] = max(_end_time, _status["ready"])

				if _status["in_degree"] == 0:
					pid = parse_pid_from_name(next_name)
					self.replayer.insert_next_node(next_name, _status["ready"])
			else:
				SingleLogger().error("{} not in status!".format(next_name))
				exit(0)

class Replayer:
	def __init__(self, dag, _step_num, leaf_dirs, dump_path, comm_backend, byteps_graph):
		self.dag = dag
		self.orig_dag = dag.copy()
		self.step_num = _step_num
		self.leaf_dirs = leaf_dirs
		self.dump_path = dump_path
		self.comm_backend = comm_backend
		self.byteps_graph = byteps_graph

		self.logger = logger_utils.SingleLogger()
		### Delay information, the unit of 'delay' field should be ms
		self.delay_dict = None
		### maintain node status
		self.node_status = {}
		self.accessed = None
		self.device_dict = {}

		self.reset_replayer()
		if self.comm_backend == "BYTEPS":
			self.op_counter = ServerOpCounter(self.byteps_graph)

	def pre_prepare(self):
		''' Initialize nodes that need to be replayed first
		'''
		def map_in_degree(n):
			if self.comm_backend == "BYTEPS":
				if self.byteps_graph.is_server_comp(n):
					return self.dag.in_degree(n) + 1
			return self.dag.in_degree(n)
		self.accessed = set()
		self.node_status = dict([(n, {"in_degree": map_in_degree(n), "ready": None}) for n in self.dag.nodes()])
		#! prepare next_nodes
		for n, _status in self.node_status.items():
			if _status["in_degree"] == 0 and n not in self.accessed:
				try:
					assert CatName.COMM.value not in n
				except:
					raise RuntimeError(n)
				pid = parse_pid_from_name(n)
				_last_end = self.step_end_time[pid] if _status["ready"] is None else _status["ready"]
				self.insert_next_node(n, _last_end)
	
	def replay_one_iter(self, step_idx):	
		self.pre_prepare()
		assert len(self.next_nodes) != 0
		while True:
			if len(self.next_nodes) == 0:
				break
			(n, t) = self.next_nodes.pop(0)
			device = self.name2device(n)
			device.exct(n, t, step_idx)
		assert len(self.node_status) == 0
		debug_utils.DebugRecorder().dump_traces(".")

	def replay(self, _output=True):
		self.reset_replayer()
		_ts = time.time()
		for step_idx in range(self.step_num):
			self.replay_one_iter(step_idx)
		self.logger.info("Take %f s to replay one iteration" % ((time.time() - _ts)/float(self.step_num)))
		if _output:
			self.output_traces()
		
	def replayAndDelay(self, delay_dict_, _ouput=False, _filename=None):
		self.reset_replayer()
		self.delay_dict = delay_dict_
		self.replay_one_iter(0)
		if _ouput:
			self.output_traces(_filename=_filename)
		return self.step_end_time

	def insert_next_node(self, n, t):
		''' This is acutally equal to a scheduler of an **Engine**
		n: node string
		t: start time of this node
		'''
		self.accessed.add(n)
		def ret_priority(n_):
			### The smaller the rank is, the higher priority the node has
			if "FW" in n_:
				return 0
			elif "OUTPUT" in n_:
				return 1
			elif "BW" in n_:
				return 2
			elif "UPDATE_" in n_:
				return 3
			else:
				return 4

		def _schedule(_a, _b):
			_ap = ret_priority(_a[0])
			_bp = ret_priority(_b[0])
			if _ap == _bp:
				### The same priority, compare the start time		
				return _a[1] < _b[1]
			else:
				return _ap < _bp
			

		#! TODO (huhanpeng): if OPs are ranked, 
		# just to substitute func to compare their ranks.
		self.insort_right(self.next_nodes, (n, t), func=_schedule)

	def insort_right(self, a, x, lo=0, hi=None, func=None):
		"""Insert item x in list a, and keep it sorted assuming a is sorted.
		If x is already in a, insert it to the right of the rightmost x.
		Optional args lo (default 0) and hi (default len(a)) bound the
		slice of a to be searched.
		"""
		def fun_cmp(x1, x2):
			if func is None:
				return x1 < x2
			else:
				return func(x1, x2)

		if lo < 0:
			raise ValueError('lo must be non-negative')
		if hi is None:
			hi = len(a)
		while lo < hi:
			mid = (lo+hi)//2
			if fun_cmp(x, a[mid]):
				hi = mid
			else:
				lo = mid+1
		a.insert(lo, x)

	def name2device(self, n):
		pid = parse_pid_from_name(n)
		cat = parse_cat_from_name(n)
		if "SEND" in n:
			device_id = gen_long_name(pid, cat, "SEND")
		elif "RECV" in n:
			device_id = gen_long_name(pid, cat, "RECV")
		else:
			device_id = gen_long_name(pid, cat)

		if device_id not in self.device_dict:
			if cat == CatName.COMM.value and self.comm_backend == "BYTEPS":
				self.device_dict[device_id] = self.create_ps_comm_device(device_id)
			else:
				self.device_dict[device_id] = self.create_device(device_id)

		return self.device_dict[device_id]		
		
	def create_device(self, device_name, infi_para=False):
		d = Device(device_name, self, comm_backend = self.comm_backend, infi_para=infi_para)
		return d

	def create_ps_comm_device(self, device_name, infi_para=False):
		d = PSCommDevice(device_name, self, self.op_counter, comm_backend = self.comm_backend, infi_para=infi_para)
		return d

	def reset_replayer(self):
		# self.step_end_time = dict([(_d, 0.0) for _d in self.leaf_dirs])
		self.step_end_time = collections.defaultdict(float)
		### nodes to be executed, in a **partial order**
		self.next_nodes = []
		self.rst_traces = []
		### Reset all devices
		for _, device_ in self.device_dict.items():
			device_.reset()

		### Ininitalize the execution graph as the depdency graph
		self.dag = self.orig_dag.copy()
		self.exct_dag = self.orig_dag.copy()

		### Add Merge nodes after each fused node
		fused_nodes = [node for node in self.dag.nodes if "+" in node]
		for node in fused_nodes:
			merge_counter = 0
			for succ in self.dag.successors(node):
				prev_edge_attrs = self.dag[node][succ]
				self.dag.remove_edge(node, succ)
				merge_node_name = "{}_MERGE{}".format(node, merge_counter)
				merge_counter += 1
				self.dag.add_node(merge_node_name, avg=0.005, GAP_STR_OP2OP=1, GAP_STR_OP2COMM=1)
				self.dag.add_edge(node, merge_node_name)
				for key, val in prev_edge_attrs.items():
					self.dag[node][merge_node_name][key] = val
				self.dag.add_edge(merge_node_name, succ, avg=0.05, GAP_STR_OP2OP=1, GAP_STR_OP2COMM=1)
			

	def output_traces(self, _filename=None):
		#! Output the synthetic traces.
		rst = {
			"traceEvents": [],
			"displayTimeUnit": "ms"
		}
		for trace in self.rst_traces:
			if "^" not in trace["name"]:
				rst["traceEvents"].append(trace)
		TraceManager(self.rst_traces, DirLevel.TRIAL).get_iter_time()
		filename = "synthetic.json" if _filename is None else _filename
		with open(os.path.join(self.dump_path, filename), 'w') as f:
			json.dump(rst, f, indent=4)

